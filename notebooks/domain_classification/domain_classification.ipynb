{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: Notebook based on the [original ReFair code](https://anonymous.4open.science/r/ReFAIR-Toward-a-Context-Aware-Fairness-Recommender-in-Requirement-Engineering-18C7/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import fasttext\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from transformers import BertTokenizer\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "dataset = pd.read_excel(\"Synthetic User Stories.xlsx\") # Change the dataset here\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for row in dataset.iterrows():\n",
    "    target.append(np.where(dataset[\"Domain\"].unique() == row[1][\"Domain\"])[0][0])\n",
    "dataset[\"Target\"] = target\n",
    "dataset[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainSetFastText():\n",
    "    #ft_model = fasttext.load_model(\"fasttext_model.bin\")\n",
    "    ft_model = fasttext.load_model(\"cc.en.100.bin\")\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        traindata.append(ft_model.get_sentence_vector(msg))\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetTFIDF():\n",
    "    countvec = CountVectorizer(max_features=100)\n",
    "    bow = countvec.fit_transform(dataset['User Story']).toarray()\n",
    "    tfidfconverter = TfidfTransformer()\n",
    "    X = tfidfconverter.fit_transform(bow).toarray()\n",
    "    training_data = pd.DataFrame(X)\n",
    "    training_data.columns = training_data.columns.astype(str)\n",
    "    return training_data\n",
    "\n",
    "def getTrainSetBERT():\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenized_data = tokenizer(dataset['User Story'].tolist(), padding=True, truncation=True, max_length=100)\n",
    "    traindata = []\n",
    "    for msg in tokenized_data['input_ids']:\n",
    "        traindata.append(msg)\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetWord2Vec():\n",
    "    #w2v_model = gensim.models.KeyedVectors.load_word2vec_format('word2vec-google-news-300.bin', binary=True)\n",
    "    w2v_model = gensim.downloader.load('word2vec-google-news-300')\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        words = msg.split()\n",
    "        vecs = []\n",
    "        for word in words:\n",
    "            if word in w2v_model:\n",
    "                vecs.append(w2v_model[word][:100])\n",
    "        if vecs:\n",
    "            vec_avg = sum(vecs) / len(vecs)\n",
    "        else:\n",
    "            vec_avg = [0] * 100\n",
    "        traindata.append(vec_avg)\n",
    "\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetGlove():\n",
    "    glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100')\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        words = msg.split()\n",
    "        vecs = []\n",
    "        for word in words:\n",
    "            if word in glove_vectors:\n",
    "                vecs.append(glove_vectors[word])\n",
    "        if vecs:\n",
    "            vec_avg = sum(vecs) / len(vecs)\n",
    "        else:\n",
    "            vec_avg = [0] * 100\n",
    "        traindata.append(vec_avg)\n",
    "\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"Fold\",\"Model\",\"Accuracy\",\"F1-Score\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "X = getTrainSetFastText()\n",
    "y = dataset['Target']\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "        print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            X[ X.index.isin(train_index)], X[ X.index.isin(test_index)], y[train_index], y[test_index]\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "        for model in models[:].iterrows():\n",
    "            result.loc[counter][\"Fold\"] = foldcounter\n",
    "            result.loc[counter][\"Model\"] = model[0]\n",
    "            result.loc[counter][\"Accuracy\"] = round(model[1][0],3)\n",
    "            result.loc[counter][\"F1-Score\"] = round(model[1][3],3)\n",
    "            counter += 1\n",
    "        foldcounter += 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"ResultFastText_domain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = result.groupby('Model')[['Accuracy', 'F1-Score']].mean().reset_index()\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"Fold\",\"Model\",\"Accuracy\",\"F1-Score\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "X = getTrainSetTFIDF() \n",
    "y = dataset['Target']\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "        print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            X[ X.index.isin(train_index)], X[ X.index.isin(test_index)], y[train_index], y[test_index]\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "        for model in models[:].iterrows():\n",
    "            result.loc[counter][\"Fold\"] = foldcounter\n",
    "            result.loc[counter][\"Model\"] = model[0]\n",
    "            result.loc[counter][\"Accuracy\"] = round(model[1][0],3)\n",
    "            result.loc[counter][\"F1-Score\"] = round(model[1][3],3)\n",
    "            counter += 1\n",
    "        foldcounter += 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"ResultTF-IDF_domain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = result.groupby('Model')[['Accuracy', 'F1-Score']].mean().reset_index()\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"Fold\",\"Model\",\"Accuracy\",\"F1-Score\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "X = getTrainSetBERT() \n",
    "y = dataset['Target']\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "        print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            X[ X.index.isin(train_index)], X[ X.index.isin(test_index)], y[train_index], y[test_index]\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "        for model in models[:].iterrows():\n",
    "            result.loc[counter][\"Fold\"] = foldcounter\n",
    "            result.loc[counter][\"Model\"] = model[0]\n",
    "            result.loc[counter][\"Accuracy\"] = round(model[1][0],3)\n",
    "            result.loc[counter][\"F1-Score\"] = round(model[1][3],3)\n",
    "            counter += 1\n",
    "        foldcounter += 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"ResultBERT_domain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = result.groupby('Model')[['Accuracy', 'F1-Score']].mean().reset_index()\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"Fold\",\"Model\",\"Accuracy\",\"F1-Score\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "X = getTrainSetWord2Vec() \n",
    "y = dataset['Target']\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "        print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            X[ X.index.isin(train_index)], X[ X.index.isin(test_index)], y[train_index], y[test_index]\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "        for model in models[:].iterrows():\n",
    "            result.loc[counter][\"Fold\"] = foldcounter\n",
    "            result.loc[counter][\"Model\"] = model[0]\n",
    "            result.loc[counter][\"Accuracy\"] = round(model[1][0],3)\n",
    "            result.loc[counter][\"F1-Score\"] = round(model[1][3],3)\n",
    "            counter += 1\n",
    "        foldcounter += 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"ResultWord2Vec_domain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = result.groupby('Model')[['Accuracy', 'F1-Score']].mean().reset_index()\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"Fold\",\"Model\",\"Accuracy\",\"F1-Score\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "X = getTrainSetGlove() \n",
    "y = dataset['Target']\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "        print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            X[ X.index.isin(train_index)], X[ X.index.isin(test_index)], y[train_index], y[test_index]\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "        for model in models[:].iterrows():\n",
    "            result.loc[counter][\"Fold\"] = foldcounter\n",
    "            result.loc[counter][\"Model\"] = model[0]\n",
    "            result.loc[counter][\"Accuracy\"] = round(model[1][0],3)\n",
    "            result.loc[counter][\"F1-Score\"] = round(model[1][3],3)\n",
    "            counter += 1\n",
    "        foldcounter += 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"ResultGlove_domain.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = result.groupby('Model')[['Accuracy', 'F1-Score']].mean().reset_index()\n",
    "average_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

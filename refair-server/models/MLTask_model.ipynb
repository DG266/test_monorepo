{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstractive summarization</td>\n",
       "      <td>Data summarization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>action model learning</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ranking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activation function</td>\n",
       "      <td>Representation learning</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Anomaly detection</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Spatio-temporal process learning</td>\n",
       "      <td>Graph diffusion</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matching</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active learning setting</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Anomaly detection</td>\n",
       "      <td>Entity resolution</td>\n",
       "      <td>Sentiment analysis</td>\n",
       "      <td>Bias detection in word embeddings</td>\n",
       "      <td>Bias detection in language models</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risk assessment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adaboost</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>word segmentation</td>\n",
       "      <td>Machine translation</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>word similarity</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Ranking</td>\n",
       "      <td>Matching</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Anomaly detection</td>\n",
       "      <td>Sentiment analysis</td>\n",
       "      <td>Entity resolution</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>word-sense disambiguation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Ranking</td>\n",
       "      <td>Matching</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Anomaly detection</td>\n",
       "      <td>Sentiment analysis</td>\n",
       "      <td>Entity resolution</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Ranking</td>\n",
       "      <td>Matching</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Anomaly detection</td>\n",
       "      <td>Sentiment analysis</td>\n",
       "      <td>Entity resolution</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wordnet</td>\n",
       "      <td>Representation learning</td>\n",
       "      <td>Clustering</td>\n",
       "      <td>Matching</td>\n",
       "      <td>Anomaly detection</td>\n",
       "      <td>Subset selection</td>\n",
       "      <td>Graph mining</td>\n",
       "      <td>Entity resolution</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0   1                          2                        3   \\\n",
       "0     classification NaN  abstractive summarization       Data summarization   \n",
       "1         regression NaN      action model learning                    Other   \n",
       "2            ranking NaN        activation function  Representation learning   \n",
       "3           matching NaN    active learning setting           Classification   \n",
       "4    risk assessment NaN                   adaboost           Classification   \n",
       "..               ...  ..                        ...                      ...   \n",
       "362              NaN NaN          word segmentation      Machine translation   \n",
       "363              NaN NaN            word similarity           Classification   \n",
       "364              NaN NaN  word-sense disambiguation           Classification   \n",
       "365              NaN NaN                   word2vec           Classification   \n",
       "366              NaN NaN                    wordnet  Representation learning   \n",
       "\n",
       "                     4                  5                  6   \\\n",
       "0                   NaN                NaN                NaN   \n",
       "1                   NaN                NaN                NaN   \n",
       "2        Classification         Regression  Anomaly detection   \n",
       "3            Regression  Anomaly detection  Entity resolution   \n",
       "4            Regression                NaN                NaN   \n",
       "..                  ...                ...                ...   \n",
       "362  Speech recognition                NaN                NaN   \n",
       "363             Ranking           Matching         Clustering   \n",
       "364             Ranking           Matching         Clustering   \n",
       "365             Ranking           Matching         Clustering   \n",
       "366          Clustering           Matching  Anomaly detection   \n",
       "\n",
       "                     7                                  8   \\\n",
       "0                   NaN                                NaN   \n",
       "1                   NaN                                NaN   \n",
       "2            Clustering   Spatio-temporal process learning   \n",
       "3    Sentiment analysis  Bias detection in word embeddings   \n",
       "4                   NaN                                NaN   \n",
       "..                  ...                                ...   \n",
       "362                 NaN                                NaN   \n",
       "363   Anomaly detection                 Sentiment analysis   \n",
       "364   Anomaly detection                 Sentiment analysis   \n",
       "365   Anomaly detection                 Sentiment analysis   \n",
       "366    Subset selection                       Graph mining   \n",
       "\n",
       "                                    9   ...   18   19   20   21   22   23  \\\n",
       "0                                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1                                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2                      Graph diffusion  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3    Bias detection in language models  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4                                  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "..                                 ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "362                                NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "363                  Entity resolution  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "364                  Entity resolution  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "365                  Entity resolution  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "366                  Entity resolution  ...  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "      24   25   26   27  \n",
       "0    NaN  NaN  NaN  NaN  \n",
       "1    NaN  NaN  NaN  NaN  \n",
       "2    NaN  NaN  NaN  NaN  \n",
       "3    NaN  NaN  NaN  NaN  \n",
       "4    NaN  NaN  NaN  NaN  \n",
       "..   ...  ...  ...  ...  \n",
       "362  NaN  NaN  NaN  NaN  \n",
       "363  NaN  NaN  NaN  NaN  \n",
       "364  NaN  NaN  NaN  NaN  \n",
       "365  NaN  NaN  NaN  NaN  \n",
       "366  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[367 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import gensim\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle\n",
    "\n",
    "glove_vectors = gensim.models.KeyedVectors.load_word2vec_format('glove.6B.100d.txt',binary=False, no_header=True)\n",
    "\n",
    "dataset = pd.read_excel(\"Synthetic User Stories.xlsx\")\n",
    "\n",
    "labels = pd.read_excel(\"Keyword labelled.xlsx\", header=None)\n",
    "labels[2] = labels[2].apply(lambda x: x.lower())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Story</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A group of researchers is using abstractive su...</td>\n",
       "      <td>[data summarization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a plant scientist, I want to use abstractiv...</td>\n",
       "      <td>[data summarization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a molecular biologist, I want to use action...</td>\n",
       "      <td>[other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a plant scientist, I want to use action mod...</td>\n",
       "      <td>[other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a bioinformatics researcher, I want to use ...</td>\n",
       "      <td>[representation learning, classification, regr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12396</th>\n",
       "      <td>As a computer vision researcher, I want to use...</td>\n",
       "      <td>[classification, ranking, matching, clustering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12397</th>\n",
       "      <td>As a network engineer, I want to use word2vec ...</td>\n",
       "      <td>[classification, ranking, matching, clustering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>As a computer vision researcher, I want to use...</td>\n",
       "      <td>[classification, ranking, matching, clustering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>As a network engineer, I want to use WordNet t...</td>\n",
       "      <td>[representation learning, clustering, matching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12400</th>\n",
       "      <td>As a computer vision researcher, I want to use...</td>\n",
       "      <td>[representation learning, clustering, matching...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              User Story  \\\n",
       "0      A group of researchers is using abstractive su...   \n",
       "1      As a plant scientist, I want to use abstractiv...   \n",
       "2      As a molecular biologist, I want to use action...   \n",
       "3      As a plant scientist, I want to use action mod...   \n",
       "4      As a bioinformatics researcher, I want to use ...   \n",
       "...                                                  ...   \n",
       "12396  As a computer vision researcher, I want to use...   \n",
       "12397  As a network engineer, I want to use word2vec ...   \n",
       "12398  As a computer vision researcher, I want to use...   \n",
       "12399  As a network engineer, I want to use WordNet t...   \n",
       "12400  As a computer vision researcher, I want to use...   \n",
       "\n",
       "                                                  Target  \n",
       "0                                   [data summarization]  \n",
       "1                                   [data summarization]  \n",
       "2                                                [other]  \n",
       "3                                                [other]  \n",
       "4      [representation learning, classification, regr...  \n",
       "...                                                  ...  \n",
       "12396  [classification, ranking, matching, clustering...  \n",
       "12397  [classification, ranking, matching, clustering...  \n",
       "12398  [classification, ranking, matching, clustering...  \n",
       "12399  [representation learning, clustering, matching...  \n",
       "12400  [representation learning, clustering, matching...  \n",
       "\n",
       "[12401 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_column = []\n",
    "for row in labels.iterrows():\n",
    "    current_labels = []\n",
    "    for label in row[1][3:]:\n",
    "        if isinstance(label, str):\n",
    "            current_labels.append(label.lower())\n",
    "    categories_column.append(current_labels)\n",
    "labels[\"Categories array\"] = categories_column\n",
    "target = []\n",
    "counter = 0\n",
    "for row in dataset.iterrows():\n",
    "    target.append(labels[labels[2]==row[1][\"Machine Learning Task\"].lower()][\"Categories array\"].values[0])\n",
    "    counter += 1\n",
    "dataset[\"Target\"] = target\n",
    "dataset[[\"User Story\",\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advertising</th>\n",
       "      <th>anomaly detection</th>\n",
       "      <th>bias detection in language models</th>\n",
       "      <th>bias detection in word embeddings</th>\n",
       "      <th>classification</th>\n",
       "      <th>clustering</th>\n",
       "      <th>data summarization</th>\n",
       "      <th>districting</th>\n",
       "      <th>entity resolution</th>\n",
       "      <th>graph augmentation</th>\n",
       "      <th>...</th>\n",
       "      <th>ranking</th>\n",
       "      <th>regression</th>\n",
       "      <th>representation learning</th>\n",
       "      <th>resource allocation</th>\n",
       "      <th>risk assessment</th>\n",
       "      <th>sentiment analysis</th>\n",
       "      <th>spatio-temporal process learning</th>\n",
       "      <th>speech recognition</th>\n",
       "      <th>subset selection</th>\n",
       "      <th>task assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12396</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12400</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12401 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       advertising  anomaly detection  bias detection in language models  \\\n",
       "0                0                  0                                  0   \n",
       "1                0                  0                                  0   \n",
       "2                0                  0                                  0   \n",
       "3                0                  0                                  0   \n",
       "4                0                  1                                  0   \n",
       "...            ...                ...                                ...   \n",
       "12396            0                  1                                  0   \n",
       "12397            0                  1                                  0   \n",
       "12398            0                  1                                  0   \n",
       "12399            0                  1                                  1   \n",
       "12400            0                  1                                  1   \n",
       "\n",
       "       bias detection in word embeddings  classification  clustering  \\\n",
       "0                                      0               0           0   \n",
       "1                                      0               0           0   \n",
       "2                                      0               0           0   \n",
       "3                                      0               0           0   \n",
       "4                                      0               1           1   \n",
       "...                                  ...             ...         ...   \n",
       "12396                                  0               1           1   \n",
       "12397                                  0               1           1   \n",
       "12398                                  0               1           1   \n",
       "12399                                  1               0           1   \n",
       "12400                                  1               0           1   \n",
       "\n",
       "       data summarization  districting  entity resolution  graph augmentation  \\\n",
       "0                       1            0                  0                   0   \n",
       "1                       1            0                  0                   0   \n",
       "2                       0            0                  0                   0   \n",
       "3                       0            0                  0                   0   \n",
       "4                       0            0                  0                   0   \n",
       "...                   ...          ...                ...                 ...   \n",
       "12396                   0            0                  1                   0   \n",
       "12397                   0            0                  1                   0   \n",
       "12398                   0            0                  1                   0   \n",
       "12399                   0            0                  1                   0   \n",
       "12400                   0            0                  1                   0   \n",
       "\n",
       "       ...  ranking  regression  representation learning  resource allocation  \\\n",
       "0      ...        0           0                        0                    0   \n",
       "1      ...        0           0                        0                    0   \n",
       "2      ...        0           0                        0                    0   \n",
       "3      ...        0           0                        0                    0   \n",
       "4      ...        0           1                        1                    0   \n",
       "...    ...      ...         ...                      ...                  ...   \n",
       "12396  ...        1           0                        0                    0   \n",
       "12397  ...        1           0                        0                    0   \n",
       "12398  ...        1           0                        0                    0   \n",
       "12399  ...        0           0                        1                    0   \n",
       "12400  ...        0           0                        1                    0   \n",
       "\n",
       "       risk assessment  sentiment analysis  spatio-temporal process learning  \\\n",
       "0                    0                   0                                 0   \n",
       "1                    0                   0                                 0   \n",
       "2                    0                   0                                 0   \n",
       "3                    0                   0                                 0   \n",
       "4                    0                   0                                 1   \n",
       "...                ...                 ...                               ...   \n",
       "12396                0                   1                                 0   \n",
       "12397                0                   1                                 0   \n",
       "12398                0                   1                                 0   \n",
       "12399                0                   1                                 0   \n",
       "12400                0                   1                                 0   \n",
       "\n",
       "       speech recognition  subset selection  task assignment  \n",
       "0                       0                 0                0  \n",
       "1                       0                 0                0  \n",
       "2                       0                 0                0  \n",
       "3                       0                 0                0  \n",
       "4                       0                 0                0  \n",
       "...                   ...               ...              ...  \n",
       "12396                   0                 0                0  \n",
       "12397                   0                 0                0  \n",
       "12398                   0                 0                0  \n",
       "12399                   0                 1                0  \n",
       "12400                   0                 1                0  \n",
       "\n",
       "[12401 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(dataset['Target'])\n",
    "pd.DataFrame(y, columns=multilabel.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainSetGlove():\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        words = msg.split()\n",
    "        vecs = []\n",
    "        for word in words:\n",
    "            if word in glove_vectors:\n",
    "                vecs.append(glove_vectors[word])\n",
    "        if vecs:\n",
    "            vec_avg = sum(vecs) / len(vecs)\n",
    "        else:\n",
    "            vec_avg = [0] * 100\n",
    "        traindata.append(vec_avg)\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelPowerset(classifier=LinearSVC(), require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelPowerset</label><div class=\"sk-toggleable__content\"><pre>LabelPowerset(classifier=LinearSVC(), require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelPowerset(classifier=LinearSVC(), require_dense=[True, True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = getTrainSetGlove()\n",
    "clf=LabelPowerset(LinearSVC())\n",
    "clf.fit(X=X.values, y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data summarization']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_story = \"A group of researchers is using abstractive summarization to identify key trends and insights in large sets of biological data, enabling more efficient analysis and interpretation.\"\n",
    "traindata = []\n",
    "for msg in [user_story]:\n",
    "    words = msg.split()\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        if word in glove_vectors:\n",
    "            vecs.append(glove_vectors[word])\n",
    "    if vecs:\n",
    "        vec_avg = sum(vecs) / len(vecs)\n",
    "    else:\n",
    "        vec_avg = [0] * 100\n",
    "    traindata.append(vec_avg)\n",
    "traindata = pd.DataFrame(traindata)\n",
    "traindata.columns = traindata.columns.astype(str)\n",
    "output = []\n",
    "for prediction in multilabel.inverse_transform(clf.predict(traindata.values))[0]:\n",
    "    output.append(prediction)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize the multilabel trasformer.\n",
    "with open('multilabel.pkl', 'wb') as f:\n",
    "    pickle.dump(multilabel, f)\n",
    "\n",
    "# Serialize the classifier\n",
    "with open('LinearSVC_LabelPowerset.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
